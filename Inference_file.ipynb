{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IISC-GROUP-5/Jupyter_Notebooks/blob/Sonali/Inference_file.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed50f917-2dd2-41c7-874e-2e09908e30ee",
      "metadata": {
        "id": "ed50f917-2dd2-41c7-874e-2e09908e30ee",
        "outputId": "2bbe83b5-b999-45c9-c0b2-508dfbf50c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully from naive_bayes_Gender_model.pkl\n",
            "Inference results saved to naive_bayes_Gender_model_inference_results.json\n",
            "Model loaded successfully from naive_bayes_Ad_click_model.pkl\n",
            "Inference results saved to naive_bayes_Ad_click_model_inference_results.json\n",
            "Model loaded successfully from svm_Gender_model.pkl\n",
            "Inference results saved to svm_Gender_model_inference_results.json\n",
            "Model loaded successfully from svm_Ad_click_model.pkl\n",
            "Inference results saved to svm_Ad_click_model_inference_results.json\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import json\n",
        "\n",
        "\n",
        "def load_model(model_file):\n",
        "    \"\"\"\n",
        "    Load the trained model from a .pkl file.\n",
        "    \"\"\"\n",
        "    with open(model_file, 'rb') as file:\n",
        "        model = pickle.load(file)\n",
        "    print(f\"Model loaded successfully from {model_file}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def preprocess_input(input_data, feature_columns, scaler=None):\n",
        "    \"\"\"\n",
        "    Preprocess the input data to match the format expected by the model,\n",
        "    applying standardization if a scaler is provided.\n",
        "    \"\"\"\n",
        "    if isinstance(input_data, dict):\n",
        "        input_df = pd.DataFrame([input_data])  # Single instance as a DataFrame\n",
        "    elif isinstance(input_data, list):\n",
        "        input_df = pd.DataFrame(input_data)  # List of instances\n",
        "    elif isinstance(input_data, pd.DataFrame):\n",
        "        input_df = input_data\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported input data format. Use dict, list, or Pandas DataFrame.\")\n",
        "\n",
        "    # Handle missing values for other columns\n",
        "    for column in input_df.columns:\n",
        "        if column != 'Age':  # 'Age' already handled\n",
        "            if input_df[column].dtype == 'object':  # Categorical data\n",
        "                most_frequent = input_df[column].mode()[0]\n",
        "                input_df[column] = input_df[column].fillna(value=most_frequent)\n",
        "            else:  # Numeric data\n",
        "                if input_df[column].isnull().sum() > 0:  # Only process columns with missing values\n",
        "                    if abs(input_df[column].skew()) >= 0.5:  # Check for skewness\n",
        "                        # Replace with absolute median\n",
        "                        median_value = abs(input_df[column].median())\n",
        "                        input_df[column] = input_df[column].fillna(value=median_value)\n",
        "                    else:\n",
        "                        # Replace with absolute mean\n",
        "                        mean_value = abs(input_df[column].mean())\n",
        "                        input_df[column] = input_df[column].fillna(value=mean_value)\n",
        "    # Replace spaces in column names with underscores\n",
        "    input_df.columns = input_df.columns.str.replace(' ', '_')\n",
        "    # Ensure only the required columns are used\n",
        "    input_df = input_df[feature_columns]\n",
        "\n",
        "    if scaler:\n",
        "        # Standardize input data using the provided scaler\n",
        "        input_df_scaled = pd.DataFrame(scaler.transform(input_df), columns=feature_columns)\n",
        "        return input_df_scaled\n",
        "    else:\n",
        "        # Return raw data if no scaling is applied\n",
        "        return input_df\n",
        "\n",
        "\n",
        "def make_prediction(model, input_data):\n",
        "    \"\"\"\n",
        "    Generate predictions and probabilities using the loaded model.\n",
        "    \"\"\"\n",
        "    predictions = model.predict(input_data)\n",
        "    probabilities = model.predict_proba(input_data) if hasattr(model, 'predict_proba') else None\n",
        "    return predictions, probabilities\n",
        "\n",
        "\n",
        "def save_inference_results(output_file, input_data, predictions, probabilities, original_data):\n",
        "    \"\"\"\n",
        "    Save the inference results to a file in JSON format.\n",
        "    The `original_data` is used to store input in the original form.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for i, row in enumerate(original_data.to_dict(orient='records')):\n",
        "        result = {\n",
        "            \"input_data\": row,\n",
        "            \"prediction\": int(predictions[i])\n",
        "        }\n",
        "        if probabilities is not None:\n",
        "            result[\"probabilities\"] = list(probabilities[i])\n",
        "        results.append(result)\n",
        "\n",
        "    # Save to a JSON file\n",
        "    with open(output_file, 'w') as file:\n",
        "        json.dump(results, file, indent=4)\n",
        "\n",
        "    print(f\"Inference results saved to {output_file}\")\n",
        "\n",
        "\n",
        "# Main inference logic\n",
        "if __name__ == \"__main__\":\n",
        "    # List of model file paths\n",
        "    model_files = [\n",
        "        \"naive_bayes_Gender_model.pkl\",\n",
        "        \"naive_bayes_Ad_click_model.pkl\",\n",
        "        \"svm_Gender_model.pkl\",\n",
        "        \"svm_Ad_click_model.pkl\"\n",
        "    ]\n",
        "\n",
        "    # Define feature columns (must match the training data)\n",
        "    feature_columns = ['Daily_Time_Spent_on_Site', 'Age', 'Area_Income', 'Daily_Internet_Usage']\n",
        "\n",
        "    # Input data for prediction (example)\n",
        "    example_input = pd.read_csv(\"Test_Data.csv\")\n",
        "    # Loop through each model file\n",
        "    for model_file in model_files:\n",
        "        # Load the trained model\n",
        "        model = load_model(model_file)\n",
        "\n",
        "        # Preprocess the input (scale the input data)\n",
        "        # scaler = StandardScaler()  # You can use a previously fitted scaler if available\n",
        "        input_data_scaled = preprocess_input(example_input, feature_columns)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions, probabilities = make_prediction(model, input_data_scaled)\n",
        "\n",
        "        # Save results to a JSON file\n",
        "        base_name = model_file.rsplit('.', 1)[0]  # Remove extension\n",
        "        output_file = f\"{base_name}_inference_results.json\"\n",
        "\n",
        "        # Save inference results in the original input data format\n",
        "        original_data = pd.DataFrame(example_input)  # Create a DataFrame with original data\n",
        "        save_inference_results(output_file, input_data_scaled, predictions, probabilities, original_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7cddc51-0366-4017-8e06-d88bfed65b98",
      "metadata": {
        "id": "b7cddc51-0366-4017-8e06-d88bfed65b98"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}